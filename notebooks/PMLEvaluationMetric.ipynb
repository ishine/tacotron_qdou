{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.expanduser('~/workspace/tacotron/'))\n",
    "\n",
    "from util import audio\n",
    "from hparams import hparams\n",
    "from lib import sigproc as sp\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tacotron.pml_synthesizer import Configuration, PMLSynthesizer\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metadata for 150 examples (0.68 hours)\n"
     ]
    }
   ],
   "source": [
    "training_data_dir = '/media/josh/Store/tacotron-data/gran-lj-training'\n",
    "metadata_filename = os.path.join(training_data_dir, 'test.txt')\n",
    "\n",
    "cfg = Configuration(16000, 86)\n",
    "synth = PMLSynthesizer(cfg)\n",
    "# synth.load(checkpoint_path, hparams, gta=gta, model_name=args.variant)\n",
    "\n",
    "with open(metadata_filename, encoding='utf-8') as f:\n",
    "    metadata = [line.strip().split('|') for line in f]\n",
    "    hours = sum((int(x[2]) for x in metadata)) * hparams.frame_shift_ms / (3600 * 1000)\n",
    "    print('Loaded metadata for %d examples (%.2f hours)' % (len(metadata), hours))\n",
    "    \n",
    "pml_features = [m[3] for m in metadata]\n",
    "texts = [m[5] for m in metadata]\n",
    "wav_files = [m[6] for m in metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989b77c7396442ca981fd8e9d25c60a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gt_wavs = []\n",
    "analysis_synthesis_wavs = []\n",
    "\n",
    "for wav_file in tqdm(wav_files):\n",
    "    gt_wav_path = os.path.join(training_data_dir, 'wavs', wav_file)\n",
    "    gt_wav = audio.load_wav(gt_wav_path)\n",
    "    gt_wavs.append(gt_wav)\n",
    "    \n",
    "    as_wav_path = os.path.join(training_data_dir, 'analysis_synthesis', wav_file)\n",
    "    as_wav = audio.load_wav(as_wav_path)\n",
    "    analysis_synthesis_wavs.append(as_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.pulsemodel import analysis\n",
    "\n",
    "# def analysis(wav, fs, f0s=None, f0_min=60, f0_max=600, f0estimator='REAPER',\n",
    "#              shift=0.005,    # Usually 5ms\n",
    "#              dftlen=4096,    # You can adapt this one according to your pipeline\n",
    "#              verbose=1):\n",
    "\n",
    "#     if verbose>0: print('PML Analysis (dur={:.3f}s, fs={}Hz, f0 in [{},{}]Hz, shift={}s, dftlen={})'.format(len(wav)/float(fs), fs, f0_min, f0_max, shift, dftlen))\n",
    "\n",
    "#     f0s = analysis_f0postproc(wav, fs, f0s, f0_min=f0_min, f0_max=f0_max, shift=shift, f0estimator=f0estimator, verbose=verbose)\n",
    "\n",
    "#     SPEC = analysis_spec(wav, fs, f0s, shift=shift, dftlen=dftlen, verbose=verbose)\n",
    "\n",
    "#     PDD = analysis_pdd(wav, fs, f0s, dftlen=dftlen, verbose=verbose)\n",
    "\n",
    "#     NM = analysis_nm(wav, fs, f0s, PDD, verbose=verbose)\n",
    "\n",
    "#     if verbose>2:\n",
    "#         plot_features(wav=wav, fs=fs, f0s=f0s, SPEC=SPEC, PDD=PDD, NM=NM) # pragma: no cover\n",
    "\n",
    "#     return f0s, SPEC, PDD, NM\n",
    "\n",
    "def pml_metric(first_set, second_set, sr_1=16000, sr_2=16000, base_sr=16000, debug=False):\n",
    "    error = 0.0\n",
    "    wav_set_size = len(first_set)\n",
    "\n",
    "    for i in range(wav_set_size):\n",
    "        wav_1 = first_set[i]\n",
    "        wav_2 = second_set[i]\n",
    "        \n",
    "        if debug:\n",
    "            print('Sample Rates:', sr_1, sr_2, base_sr)\n",
    "        \n",
    "        if sr_1 != base_sr:\n",
    "            wav_1 = librosa.core.resample(wav_1, orig_sr=sr_1, target_sr=base_sr)\n",
    "        \n",
    "        if sr_2 != base_sr:\n",
    "            wav_2 = librosa.core.resample(wav_2, orig_sr=sr_2, target_sr=base_sr)\n",
    "        \n",
    "        cutoff = min(len(wav_1), len(wav_2))\n",
    "        f0s_1, _, _, _ = analysis(np.array(wav_1[:cutoff], dtype=np.int16), base_sr)\n",
    "        f0s_2, _, _, _ = analysis(np.array(wav_2[:cutoff], dtype=np.int16), base_sr)\n",
    "\n",
    "        error += np.mean(np.square(f0s_1 - f0s_2))\n",
    "\n",
    "    error = np.sqrt(error / wav_set_size)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PML Analysis (dur=6.776s, fs=22050Hz, f0 in [60,600]Hz, shift=0.005s, dftlen=4096)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dev/shm/josh/sigproc.pid2433.6b6278a5-67e1-41c3-bd7c-3748a64fa2db.interface-reaper-out.f0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3d8d42047b6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpml_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_wavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_synthesis_wavs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_sr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-2674e8745158>\u001b[0m in \u001b[0;36mpml_metric\u001b[0;34m(first_set, second_set, sr_1, sr_2, base_sr, debug)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mf0s_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_sr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mf0s_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_sr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/tacotron/lib/pulsemodel/analysis.py\u001b[0m in \u001b[0;36manalysis\u001b[0;34m(wav, fs, f0s, f0_min, f0_max, f0estimator, shift, dftlen, verbose)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PML Analysis (dur={:.3f}s, fs={}Hz, f0 in [{},{}]Hz, shift={}s, dftlen={})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdftlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     \u001b[0mf0s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_f0postproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf0_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf0_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf0estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mSPEC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdftlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdftlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/tacotron/lib/pulsemodel/analysis.py\u001b[0m in \u001b[0;36manalysis_f0postproc\u001b[0;34m(wav, fs, f0s, f0_min, f0_max, shift, f0estimator, verbose)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf0s\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# TODO Switch f0 estimator using `f0estimator`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mf0s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreaper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# If only values are given, make two column matrix [time[s], value[Hz]] (ljuvela)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/tacotron/lib/sigproc/interfaces.py\u001b[0m in \u001b[0;36mreaper\u001b[0;34m(wav, fs, shift, f0min, f0max, rmsteps, outpm, prehp_cutoff)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Read the f0 values and the corresponding analysis times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mf0s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpf0file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf0file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf0file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dev/shm/josh/sigproc.pid2433.6b6278a5-67e1-41c3-bd7c-3748a64fa2db.interface-reaper-out.f0'"
     ]
    }
   ],
   "source": [
    "pml_metric(gt_wavs, analysis_synthesis_wavs, sr_1=22050, sr_2=22050, base_sr=22050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
